{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from time import sleep\n",
    "import itertools\n",
    "from datetime import timedelta\n",
    "import diffdist.functional as distops\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, input_num_filters, output_num_filters, filter_size):\n",
    "        super(MyConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_num_filters, output_num_filters, kernel_size=(filter_size, filter_size))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        return x\n",
    "\n",
    "class MyOutputModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, ouput_size):\n",
    "        super(MyOutputModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, ouput_size)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipelineModel(nn.Module):\n",
    "    def __init__(self, models, num_worker, split_size=32):\n",
    "        super(MyPipelineModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.num_worker = num_worker\n",
    "        self.split_size = split_size\n",
    "        self.optimizers = [optim.Adam(self.models[0].parameters(), lr=0.001), optim.Adam(self.models[1].parameters(), lr=0.001), optim.Adam(self.models[2].parameters(), lr=0.001)]\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.epochs = 5\n",
    "        #self.batch_size = 100\n",
    "        self.running_loss = 0\n",
    "        \n",
    "    def run(self, x):\n",
    "        processes = []\n",
    "        \n",
    "        for rank in range(self.num_worker):\n",
    "            p = mp.Process(target=self.init_process, args=(rank, self.num_worker, x, self.forward))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        \n",
    "    def init_process(self, rank, size, x, fn, backend='gloo'):\n",
    "        torch.set_num_threads(2)\n",
    "        os.environ['GLOO_SOCKET_IFNAME']='lo'\n",
    "        os.environ['MASTER_ADDR'] = 'localhost'\n",
    "        os.environ['MASTER_PORT'] = '3000'\n",
    "        dist.init_process_group(backend, rank=rank, world_size=size)\n",
    "        fn(rank, size, x)\n",
    "        \n",
    "    def forward(self, rank, size, x):\n",
    "        time0 = time()\n",
    "        for e in range(self.epochs):\n",
    "            if rank == self.num_worker-1:\n",
    "                self.running_loss = 0\n",
    "            \n",
    "            for images, labels in x:\n",
    "                rank = dist.get_rank()\n",
    "                splits = iter(images.split(self.split_size, dim=0))\n",
    "                s_next = next(splits)\n",
    "                splits_value = [None, torch.zeros((32, 16, 12, 12)), torch.zeros((32, 32, 4, 4))]\n",
    "                self.optimizers[rank].zero_grad()\n",
    "                \n",
    "                if rank == self.num_worker-1:\n",
    "                    ret = []\n",
    "                \n",
    "                \n",
    "                if rank == self.num_worker-1:\n",
    "                    dist.recv(tensor=splits_value[rank], src=rank-1)\n",
    "                    splits_value[rank] = Variable(splits_value[rank], requires_grad = True)\n",
    "                    output = self.models[rank](splits_value[rank])\n",
    "                    ret.append(output)\n",
    "                    print(splits_value[rank].requires_grad)\n",
    "\n",
    "                elif rank == 0:\n",
    "                    output = self.models[0](s_next)\n",
    "                    dist.send(tensor=output, dst=1)\n",
    "                    print(output.requires_grad)\n",
    "                else:\n",
    "                    dist.recv(tensor=splits_value[rank], src=rank-1)\n",
    "                    splits_value[rank] = Variable(splits_value[rank], requires_grad = True)\n",
    "                    output = self.models[rank](splits_value[rank])\n",
    "                    dist.send(tensor=output, dst=rank+1)\n",
    "                \n",
    "                \n",
    "                for s_next in splits:\n",
    "                    if rank == self.num_worker-1:\n",
    "                        dist.recv(tensor=splits_value[rank], src=rank-1)\n",
    "                        splits_value[rank] = Variable(splits_value[rank], requires_grad = True)\n",
    "                        output = self.models[rank](splits_value[rank])\n",
    "                        ret.append(output)\n",
    "\n",
    "                    elif rank == 0:\n",
    "                        output = self.models[0](s_next)\n",
    "                        dist.send(tensor=output, dst=1)\n",
    "                    else:\n",
    "                        dist.recv(tensor=splits_value[rank], src=rank-1)\n",
    "                        splits_value[rank] = Variable(splits_value[rank], requires_grad = True)\n",
    "                        output = self.models[rank](splits_value[rank])\n",
    "                        dist.send(tensor=output, dst=rank+1)\n",
    "                        \n",
    "                if rank == self.num_worker-1:\n",
    "                    output = torch.cat(ret)\n",
    "                    loss = self.criterion(output, labels)\n",
    "                    \n",
    "                    for i in range(self.num_worker-1):\n",
    "                        dist.send(tensor=loss, dst=i, tag=i)\n",
    "                else:\n",
    "                    loss = torch.zeros((1))\n",
    "                    dist.recv(tensor=loss, src=self.num_worker-1, tag=rank)\n",
    "                    \n",
    "                    loss = Variable(loss, requires_grad = True)\n",
    "\n",
    "                print(\"Rank :\", rank, torch.autograd.grad(loss, self.models[rank].parameters()))\n",
    "\n",
    "                self.optimizers[rank].step()\n",
    "                self.running_loss += loss.item()\n",
    "            \n",
    "            if rank == self.num_worker-1:\n",
    "                print(\"Epoch {} - Training loss: {}\".format(e, self.running_loss/len(trainloader)))\n",
    "                print(\"\\nTraining Time (in seconds) =\",(time()-time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = nn.ModuleList()\n",
    "models.append(MyConvModel(1, 16, 5))\n",
    "models.append(MyConvModel(16, 32, 5))\n",
    "models.append(MyOutputModel(512, 128, 10))\n",
    "\n",
    "model = MyPipelineModel(models, len(models))\n",
    "model.run(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
