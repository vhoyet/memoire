{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from time import sleep\n",
    "import threading, queue\n",
    "import concurrent.futures\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "print(type(trainset))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, input_num_filters, output_num_filters, filter_size):\n",
    "        super(MyConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_num_filters, output_num_filters, kernel_size=(filter_size, filter_size))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        return x\n",
    "\n",
    "class MyOutputModel(nn.Module):\n",
    "    def __init__(self, input_num_filters, output_num_filters, filter_size, input_size, hidden_size, ouput_size):\n",
    "        super(MyOutputModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_num_filters, output_num_filters, kernel_size=(filter_size, filter_size))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, ouput_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipelineModel(nn.Module):\n",
    "    def __init__(self, models, split_size=32):\n",
    "        super(MyPipelineModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.split_size = split_size\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.epochs = 5\n",
    "        self.batch_size = 100\n",
    "        self.running_loss = 0\n",
    "        self.tensor_q = queue.Queue()\n",
    "        self.backward_q = queue.Queue()\n",
    "        \n",
    "    def run(self, x):\n",
    "        size = 2\n",
    "        processes = []\n",
    "        \n",
    "        for rank in range(size):\n",
    "            p = threading.Thread(target=self.train, args=(x, rank, size))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        self.backward_q.join()\n",
    "        self.tensor_q.join()\n",
    "        \n",
    "    def train(self, x, rank, size):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        time0 = time()\n",
    "        for e in range(self.epochs):\n",
    "            if rank == 0:\n",
    "                self.running_loss = 0\n",
    "            \n",
    "            for images, labels in x:\n",
    "                splits = iter(images.split(self.split_size, dim=0))\n",
    "                s_next = next(splits)\n",
    "                \n",
    "                if rank == 0:\n",
    "                    self.optimizer.zero_grad()\n",
    "                    s_prev = self.models[0](s_next)\n",
    "                    ret = []\n",
    "\n",
    "                for s_next in splits:\n",
    "                    if rank == 0:\n",
    "                        output = self.models[1](s_prev)\n",
    "                        ret.append(output)\n",
    "                        if not self.tensor_q.empty():\n",
    "                            self.tensor_q.task_done()\n",
    "                        s_prev = self.tensor_q.get()\n",
    "                    else:\n",
    "                        self.tensor_q.put(self.models[0](s_next))\n",
    "                \n",
    "                if rank == 0:\n",
    "                    ret.append(self.models[1](s_prev))\n",
    "                    output = torch.cat(ret)\n",
    "                    loss = self.criterion(output, labels)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    self.backward_q.put(\"Backward done.\")\n",
    "                    self.running_loss += loss.item()\n",
    "                else:\n",
    "                    tmp = self.backward_q.get()\n",
    "                    self.backward_q.task_done()\n",
    "                    \n",
    "            if rank == 0:\n",
    "                print(\"Epoch {} - Training loss: {}\".format(e, self.running_loss/len(trainloader)))\n",
    "                print(\"\\nTraining Time (in seconds) =\",(time()-time0))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = nn.ModuleList()\n",
    "models.append(MyConvModel(1, 16, 5))\n",
    "models.append(MyOutputModel(16, 32, 5, 512, 128, 10))\n",
    "\n",
    "model = MyPipelineModel(models)\n",
    "model.run(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
