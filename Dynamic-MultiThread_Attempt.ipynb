{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from time import sleep\n",
    "import threading, queue\n",
    "import concurrent.futures\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "print(type(trainset))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8192, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=8192, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConvModel(nn.Module):\n",
    "    def __init__(self, input_num_filters, output_num_filters, filter_size):\n",
    "        super(MyConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_num_filters, output_num_filters, kernel_size=(filter_size, filter_size))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        return x\n",
    "\n",
    "class MyOutputModel_3threads(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, ouput_size):\n",
    "        super(MyOutputModel_3threads, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, ouput_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MyOutputModel_2threads(nn.Module):\n",
    "    def __init__(self, input_num_filters, output_num_filters, filter_size, input_size, hidden_size, ouput_size):\n",
    "        super(MyOutputModel_2threads, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_num_filters, output_num_filters, kernel_size=(filter_size, filter_size))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, ouput_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipelineModel(nn.Module):\n",
    "    def __init__(self, models, num_workers, split_size=2048):\n",
    "        super(MyPipelineModel, self).__init__()\n",
    "        self.models = models\n",
    "        self.num_workers = num_workers\n",
    "        self.split_size = split_size\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.epochs = 5\n",
    "        self.batch_size = 100\n",
    "        self.running_loss = 0\n",
    "        \n",
    "    def run(self, x):\n",
    "        size = 2\n",
    "        processes = []\n",
    "        \n",
    "        for rank in range(size):\n",
    "            p = threading.Thread(target=self.train, args=(x, rank, size))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        self.backward_q.join()\n",
    "        self.tensor_q.join()\n",
    "        \n",
    "    def train(self, x):\n",
    "        time0 = time()\n",
    "        for e in range(self.epochs):\n",
    "            self.running_loss = 0\n",
    "            \n",
    "            for images, labels in x:\n",
    "                splits = iter(images.split(self.split_size, dim=0))\n",
    "                s_next = next(splits)\n",
    "                splits_value = [None] * self.num_workers\n",
    "                thread_models = [None] * self.num_workers\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                splits_value[1] = self.models[0](s_next)\n",
    "                ret = []\n",
    "\n",
    "                for s_next in splits:\n",
    "                    splits_value[0] = s_next\n",
    "                    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "                        \n",
    "                        for i in range(self.num_workers):\n",
    "                            if not splits_value[i] == None:\n",
    "                                thread_models[i] = executor.submit(self.models[i].forward, splits_value[i])\n",
    "                                \n",
    "                        for i in range(self.num_workers):\n",
    "                            if i == self.num_workers-1 and not thread_models[i] == None:\n",
    "                                ret.append(thread_models[i].result())\n",
    "                            elif not thread_models[i] == None:\n",
    "                                splits_value[i+1] = thread_models[i].result()\n",
    "                    \n",
    "                \n",
    "                splits_value[0] = None\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "                    for j in range(self.num_workers-2):\n",
    "                        for i in range(self.num_workers):\n",
    "                            if not splits_value[i] == None:\n",
    "                                thread_models[i] = executor.submit(self.models[i].forward, splits_value[i])\n",
    "                                \n",
    "                        for i in range(self.num_workers):\n",
    "                            if i == self.num_workers-1 and not thread_models[i] == None:\n",
    "                                ret.append(thread_models[i].result())\n",
    "                            elif not thread_models[i] == None:\n",
    "                                splits_value[i+1] = thread_models[i].result()\n",
    "                        splits_value[j+1] = None\n",
    "               \n",
    "                ret.append(self.models[self.num_workers-1](splits_value[self.num_workers-1]))\n",
    "                output = torch.cat(ret)\n",
    "                loss = self.criterion(output, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.running_loss += loss.item()\n",
    "                    \n",
    "            print(\"Epoch {} - Training loss: {}\".format(e, self.running_loss/len(trainloader)))\n",
    "            print(\"\\nTraining Time (in seconds) =\",(time()-time0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig on 3 threads\n",
      "Epoch 0 - Training loss: 2.13895620405674\n",
      "\n",
      "Training Time (in seconds) = 10.835822343826294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a19cce8c81ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyPipelineModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-1b4291c305fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#print(\"training on 2 threads\")\n",
    "#models = nn.ModuleList()\n",
    "#models.append(MyConvModel(1, 16, 5))\n",
    "#models.append(MyOutputModel_2threads(16, 32, 5, 512, 128, 10))\n",
    "\n",
    "#model = MyPipelineModel(models, len(models))\n",
    "#model.train(trainloader)\n",
    "\n",
    "\n",
    "print(\"training on 3 threads\")\n",
    "models = nn.ModuleList()\n",
    "models.append(MyConvModel(1, 16, 5))\n",
    "models.append(MyConvModel(16, 32, 5))\n",
    "models.append(MyOutputModel_3threads(512, 128, 10))\n",
    "\n",
    "model = MyPipelineModel(models, len(models))\n",
    "model.train(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
